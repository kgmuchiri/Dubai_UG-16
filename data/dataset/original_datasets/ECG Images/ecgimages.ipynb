{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECG Images Preprocessing\n",
    "Taking a single patients ECG image and seperates them into 12 images, one for each lead\n",
    "retrieved from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from skimage.filters import threshold_otsu, gaussian\n",
    "from skimage import measure, color, morphology, filters,io\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread, imsave\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting and Preprocessing Images\n",
    "    \n",
    "Extracts individual leads from an ECG image, preprocesses them to remove noise \n",
    "and keep only the ECG signal, and saves the smaller resulting images\n",
    "\n",
    "Arguments:\n",
    "  image_file: Name of the input image file.\n",
    "  parent_folder: Path to the folder containing the image file.\n",
    "  output_folder: Path to the folder where the processed lead images will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_preprocess_leads(image_file, parent_folder, output_folder):\n",
    "    # Read the image\n",
    "    image = imread(os.path.join(parent_folder, image_file))\n",
    "\n",
    "    # Dividing the ECG leads with offset\n",
    "    start_offset = 30 \n",
    "\n",
    "    Lead_1 = image[300:600, 150 + start_offset:643]\n",
    "    Lead_2 = image[300:600, 646 + start_offset:1135]\n",
    "    Lead_3 = image[300:600, 1140 + start_offset:1626]\n",
    "    Lead_4 = image[300:600, 1630 + start_offset:2125]\n",
    "    Lead_5 = image[600:900, 150 + start_offset:643]\n",
    "    Lead_6 = image[600:900, 646 + start_offset:1135]\n",
    "    Lead_7 = image[600:900, 1140 + start_offset:1626]\n",
    "    Lead_8 = image[600:900, 1630 + start_offset:2125]\n",
    "    Lead_9 = image[900:1200, 150 + start_offset:643]\n",
    "    Lead_10 = image[900:1200, 646 + start_offset:1135]\n",
    "    Lead_11 = image[900:1200, 1140 + start_offset:1626]\n",
    "    Lead_12 = image[900:1200, 1630 + start_offset:2125]\n",
    "\n",
    "    Leads=[Lead_1,Lead_2,Lead_3,Lead_4,Lead_5,Lead_6,Lead_7,Lead_8,Lead_9,Lead_10,Lead_11,Lead_12]\n",
    "\n",
    "     # Extract the original filename without extension\n",
    "    base_filename = os.path.splitext(image_file)[0]\n",
    "\n",
    "    # Extract the class label from the base filename\n",
    "    class_label = re.match(r'([^\\(]+)', base_filename).group(1) \n",
    "    folder_name = re.sub('.jpg', '', image_file)\n",
    "    output_path = os.path.join(output_folder, folder_name)\n",
    "\n",
    "    for x, lead_img in enumerate(Leads):\n",
    "        # Convert to grayscale\n",
    "        grayscale = color.rgb2gray(lead_img)\n",
    "        # Smooth the image\n",
    "        blurred_image = gaussian(grayscale, sigma=0.7)\n",
    "        # Thresholding\n",
    "        global_thresh = filters.threshold_otsu(blurred_image)\n",
    "        binary_global = blurred_image < global_thresh \n",
    "        # Morphological Operations (Connect broken segments)\n",
    "        binary_global = morphology.closing(binary_global, morphology.square(3)) \n",
    "        # Resize\n",
    "        binary_global = resize(binary_global, (180,230))\n",
    "       \n",
    "        # Find contours to isolate the ECG signal\n",
    "        contours = measure.find_contours(binary_global, 0.8)\n",
    "        contours_shape = sorted([x.shape for x in contours])[::-1][0:1]\n",
    "        # Create a blank image to draw the extracted signal\n",
    "        extracted_signal = np.zeros_like(binary_global)\n",
    "        for contour in contours:\n",
    "            if contour.shape in contours_shape:\n",
    "                # Draw the contour on the blank image\n",
    "                for point in contour:\n",
    "                    x_coord, y_coord = int(point[1]), int(point[0])\n",
    "                    extracted_signal[y_coord, x_coord] = 1  # Set pixel to white\n",
    "        \n",
    "\n",
    "        # Create the output filename with the desired convention\n",
    "        output_filename = f\"{base_filename}_lead_{x+1}.png\"  \n",
    "        output_path = os.path.join(output_folder, output_filename)  # Save directly to output_folder\n",
    "        # Save the extracted signal image\n",
    "        imsave(output_path, extracted_signal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor class_label in ['AB', 'HMI', 'MI', 'Normal']:\\n    class_path = os.path.join(input_folder, class_label)\\n    for filename in os.listdir(class_path):\\n        if filename.endswith(('.png', '.jpg', '.jpeg')):\\n            extract_and_preprocess_leads(filename, class_path, output_folder)\\n\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "input_folder = '.'  # Input folder\n",
    "output_folder = './trial'  # Desired output folder\n",
    "\n",
    "# Iterate over each class folder and extract and preprocess the leads\n",
    "# Uncomment to run\n",
    "'''\n",
    "for class_label in ['AB', 'HMI', 'MI', 'Normal']:\n",
    "    class_path = os.path.join(input_folder, class_label)\n",
    "    for filename in os.listdir(class_path):\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            extract_and_preprocess_leads(filename, class_path, output_folder)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_stitch_ecg_leads(image_file, parent_folder, output_folder):\n",
    "    # Read the image\n",
    "    image = io.imread(os.path.join(parent_folder, image_file))\n",
    "\n",
    "    # Dividing the ECG leads with offset\n",
    "    start_offset = 30 \n",
    "\n",
    "    Lead_1 = image[300:600, 150 + start_offset:643]\n",
    "    Lead_2 = image[300:600, 646 + start_offset:1135]\n",
    "    Lead_3 = image[300:600, 1140 + start_offset:1626]\n",
    "    Lead_4 = image[300:600, 1630 + start_offset:2125]\n",
    "    Lead_5 = image[600:900, 150 + start_offset:643]\n",
    "    Lead_6 = image[600:900, 646 + start_offset:1135]\n",
    "    Lead_7 = image[600:900, 1140 + start_offset:1626]\n",
    "    Lead_8 = image[600:900, 1630 + start_offset:2125]\n",
    "    Lead_9 = image[900:1200, 150 + start_offset:643]\n",
    "    Lead_10 = image[900:1200, 646 + start_offset:1135]\n",
    "    Lead_11 = image[900:1200, 1140 + start_offset:1626]\n",
    "    Lead_12 = image[900:1200, 1630 + start_offset:2125]\n",
    "\n",
    "    Leads=[Lead_1,Lead_2,Lead_3,Lead_4,Lead_5,Lead_6,Lead_7,Lead_8,Lead_9,Lead_10,Lead_11,Lead_12]\n",
    "\n",
    "    processed_leads = []\n",
    "    for lead_img in Leads:\n",
    "        # Convert to grayscale\n",
    "        grayscale = color.rgb2gray(lead_img)\n",
    "        # Smooth the image\n",
    "        blurred_image = filters.gaussian(grayscale, sigma=0.7)\n",
    "        # Thresholding\n",
    "        global_thresh = filters.threshold_otsu(blurred_image)\n",
    "        binary_global = blurred_image < global_thresh \n",
    "        # Morphological Operations (Connect broken segments)\n",
    "        binary_global = morphology.closing(binary_global, morphology.square(3)) \n",
    "        # Resize\n",
    "        binary_global = resize(binary_global, (180,230))\n",
    "\n",
    "        # Find contours to isolate the ECG signal (optional, if needed)\n",
    "        contours = measure.find_contours(binary_global, 0.8)\n",
    "        contours_shape = sorted([x.shape for x in contours])[::-1][0:1]\n",
    "        extracted_signal = np.zeros_like(binary_global)\n",
    "        for contour in contours:\n",
    "            if contour.shape in contours_shape:\n",
    "                for point in contour:\n",
    "                    x_coord, y_coord = int(point[1]), int(point[0])\n",
    "                    extracted_signal[y_coord, x_coord] = 1 \n",
    "\n",
    "        processed_leads.append(extracted_signal)\n",
    "\n",
    "    # Stitch the leads together\n",
    "    top_row = np.concatenate(processed_leads[:4], axis=1)  # Leads 1 to 4\n",
    "    middle_row = np.concatenate(processed_leads[4:8], axis=1)  # Leads 5 to 8\n",
    "    bottom_row = np.concatenate(processed_leads[8:], axis=1)  # Leads 9 to 12\n",
    "    stitched_image = np.concatenate([top_row, middle_row, bottom_row], axis=0)\n",
    "\n",
    "    # Extract the original filename without extension\n",
    "    base_filename = os.path.splitext(image_file)[0]\n",
    "\n",
    "    # Create the output filename \n",
    "    output_filename = f\"{base_filename}_stitched.png\" \n",
    "    output_path = os.path.join(output_folder, output_filename)  \n",
    "    # Save the stitched image\n",
    "    io.imsave(output_path, stitched_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_78895/612620716.py:62: UserWarning: ./trial/HB(108)_stitched.png is a boolean image: setting True to 255 and False to 0. To silence this warning, please convert the image using img_as_ubyte.\n",
      "  io.imsave(output_path, stitched_image)\n",
      "/tmp/ipykernel_78895/612620716.py:62: UserWarning: ./trial/HB(139)_stitched.png is a boolean image: setting True to 255 and False to 0. To silence this warning, please convert the image using img_as_ubyte.\n",
      "  io.imsave(output_path, stitched_image)\n",
      "/tmp/ipykernel_78895/612620716.py:62: UserWarning: ./trial/HB(217)_stitched.png is a boolean image: setting True to 255 and False to 0. To silence this warning, please convert the image using img_as_ubyte.\n",
      "  io.imsave(output_path, stitched_image)\n",
      "/tmp/ipykernel_78895/612620716.py:62: UserWarning: ./trial/HB(10)_stitched.png is a boolean image: setting True to 255 and False to 0. To silence this warning, please convert the image using img_as_ubyte.\n",
      "  io.imsave(output_path, stitched_image)\n",
      "/tmp/ipykernel_78895/612620716.py:62: UserWarning: ./trial/HB(79)_stitched.png is a boolean image: setting True to 255 and False to 0. To silence this warning, please convert the image using img_as_ubyte.\n",
      "  io.imsave(output_path, stitched_image)\n",
      "/tmp/ipykernel_78895/612620716.py:62: UserWarning: ./trial/HB(147)_stitched.png is a boolean image: setting True to 255 and False to 0. To silence this warning, please convert the image using img_as_ubyte.\n",
      "  io.imsave(output_path, stitched_image)\n",
      "/tmp/ipykernel_78895/612620716.py:62: UserWarning: ./trial/HB(100)_stitched.png is a boolean image: setting True to 255 and False to 0. To silence this warning, please convert the image using img_as_ubyte.\n",
      "  io.imsave(output_path, stitched_image)\n",
      "/tmp/ipykernel_78895/612620716.py:62: UserWarning: ./trial/HB(149)_stitched.png is a boolean image: setting True to 255 and False to 0. To silence this warning, please convert the image using img_as_ubyte.\n",
      "  io.imsave(output_path, stitched_image)\n",
      "/tmp/ipykernel_78895/612620716.py:62: UserWarning: ./trial/HB(154)_stitched.png is a boolean image: setting True to 255 and False to 0. To silence this warning, please convert the image using img_as_ubyte.\n",
      "  io.imsave(output_path, stitched_image)\n",
      "/tmp/ipykernel_78895/612620716.py:62: UserWarning: ./trial/HB(126)_stitched.png is a boolean image: setting True to 255 and False to 0. To silence this warning, please convert the image using img_as_ubyte.\n",
      "  io.imsave(output_path, stitched_image)\n",
      "/tmp/ipykernel_78895/612620716.py:62: UserWarning: ./trial/HB(6)_stitched.png is a boolean image: setting True to 255 and False to 0. To silence this warning, please convert the image using img_as_ubyte.\n",
      "  io.imsave(output_path, stitched_image)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(class_path):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpeg\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m----> 5\u001b[0m         extract_and_stitch_ecg_leads(filename, class_path, output_folder)\n",
      "Cell \u001b[0;32mIn[4], line 30\u001b[0m, in \u001b[0;36mextract_and_stitch_ecg_leads\u001b[0;34m(image_file, parent_folder, output_folder)\u001b[0m\n\u001b[1;32m     28\u001b[0m blurred_image \u001b[38;5;241m=\u001b[39m filters\u001b[38;5;241m.\u001b[39mgaussian(grayscale, sigma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Thresholding\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m global_thresh \u001b[38;5;241m=\u001b[39m filters\u001b[38;5;241m.\u001b[39mthreshold_otsu(blurred_image)\n\u001b[1;32m     31\u001b[0m binary_global \u001b[38;5;241m=\u001b[39m blurred_image \u001b[38;5;241m<\u001b[39m global_thresh \n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Morphological Operations (Connect broken segments)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/skimage/filters/thresholding.py:390\u001b[0m, in \u001b[0;36mthreshold_otsu\u001b[0;34m(image, nbins, hist)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(image \u001b[38;5;241m==\u001b[39m first_pixel):\n\u001b[1;32m    388\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m first_pixel\n\u001b[0;32m--> 390\u001b[0m counts, bin_centers \u001b[38;5;241m=\u001b[39m _validate_image_histogram(image, hist, nbins)\n\u001b[1;32m    392\u001b[0m \u001b[38;5;66;03m# class probabilities for all possible thresholds\u001b[39;00m\n\u001b[1;32m    393\u001b[0m weight1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcumsum(counts)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/skimage/filters/thresholding.py:330\u001b[0m, in \u001b[0;36m_validate_image_histogram\u001b[0;34m(image, hist, nbins, normalize)\u001b[0m\n\u001b[1;32m    328\u001b[0m         counts, bin_centers \u001b[38;5;241m=\u001b[39m counts[start:end], bin_centers[start:end]\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 330\u001b[0m     counts, bin_centers \u001b[38;5;241m=\u001b[39m histogram(\n\u001b[1;32m    331\u001b[0m         image\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), nbins, source_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m, normalize\u001b[38;5;241m=\u001b[39mnormalize\n\u001b[1;32m    332\u001b[0m     )\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m counts\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), bin_centers\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/skimage/_shared/utils.py:438\u001b[0m, in \u001b[0;36mchannel_as_last_axis.__call__.<locals>.fixed_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    435\u001b[0m channel_axis \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchannel_axis\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m channel_axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;66;03m# TODO: convert scalars to a tuple in anticipation of eventually\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;66;03m#       supporting a tuple of channel axes. Right now, only an\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;66;03m#       integer or a single-element tuple is supported, though.\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(channel_axis):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/skimage/exposure/exposure.py:274\u001b[0m, in \u001b[0;36mhistogram\u001b[0;34m(image, nbins, source_range, normalize, channel_axis)\u001b[0m\n\u001b[1;32m    272\u001b[0m     hist \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(hist, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     hist, bin_centers \u001b[38;5;241m=\u001b[39m _histogram(image, nbins, source_range, normalize)\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hist, bin_centers\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/skimage/exposure/exposure.py:306\u001b[0m, in \u001b[0;36m_histogram\u001b[0;34m(image, bins, source_range, normalize)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    305\u001b[0m     hist_range \u001b[38;5;241m=\u001b[39m _get_numpy_hist_range(image, source_range)\n\u001b[0;32m--> 306\u001b[0m     hist, bin_edges \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhistogram(image, bins\u001b[38;5;241m=\u001b[39mbins, \u001b[38;5;28mrange\u001b[39m\u001b[38;5;241m=\u001b[39mhist_range)\n\u001b[1;32m    307\u001b[0m     bin_centers \u001b[38;5;241m=\u001b[39m (bin_edges[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m bin_edges[\u001b[38;5;241m1\u001b[39m:]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2.0\u001b[39m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m normalize:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/numpy/lib/histograms.py:841\u001b[0m, in \u001b[0;36mhistogram\u001b[0;34m(a, bins, range, density, weights)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;66;03m# Compute the bin indices, and for values that lie exactly on\u001b[39;00m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;66;03m# last_edge we need to subtract one\u001b[39;00m\n\u001b[1;32m    839\u001b[0m f_indices \u001b[38;5;241m=\u001b[39m ((_unsigned_subtract(tmp_a, first_edge) \u001b[38;5;241m/\u001b[39m norm_denom)\n\u001b[1;32m    840\u001b[0m              \u001b[38;5;241m*\u001b[39m norm_numerator)\n\u001b[0;32m--> 841\u001b[0m indices \u001b[38;5;241m=\u001b[39m f_indices\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mintp)\n\u001b[1;32m    842\u001b[0m indices[indices \u001b[38;5;241m==\u001b[39m n_equal_bins] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;66;03m# The index computation is not guaranteed to give exactly\u001b[39;00m\n\u001b[1;32m    845\u001b[0m \u001b[38;5;66;03m# consistent results within ~1 ULP of the bin edges.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for class_label in ['AB', 'HMI', 'MI', 'Normal']:\n",
    "    class_path = os.path.join(input_folder, class_label)\n",
    "    for filename in os.listdir(class_path):\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            extract_and_stitch_ecg_leads(filename, class_path, output_folder)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
