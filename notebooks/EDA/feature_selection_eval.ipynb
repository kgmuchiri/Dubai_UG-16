{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = pd.read_csv('../../data/dataset/feature_selection/data_encoded_10_features.csv')\n",
    "dataset2 = pd.read_csv('../../data/dataset/feature_selection/data_encoded_20_features.csv')\n",
    "dataset3 = pd.read_csv('../../data/dataset/feature_selection/data_encoded_41_features.csv')\n",
    "dataset_re_1 = pd.read_csv('../../data/dataset/feature_selection/resample_encoded_10_features.csv')\n",
    "dataset_re_2 = pd.read_csv('../../data/dataset/feature_selection/resample_encoded_20_features.csv')\n",
    "dataset_re_3 = pd.read_csv('../../data/dataset/feature_selection/resample_encoded_41_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = dataset1.drop('HeartDisease_Yes', axis=1) \n",
    "y1 = dataset1['HeartDisease_Yes']\n",
    "X2 = dataset2.drop('HeartDisease_Yes', axis=1)\n",
    "y2 = dataset2['HeartDisease_Yes']\n",
    "X3 = dataset3.drop('HeartDisease_Yes', axis=1)\n",
    "y3 = dataset3['HeartDisease_Yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.3, random_state=42)\n",
    "X2_train, X2_test, y2_train,y2_test = train_test_split(X2, y2, test_size=0.3, random_state=42)\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Dataset 1:\n",
      "  Accuracy: 0.9098\n",
      "  TP rate: 0.0602\n",
      "  FP rate: 0.0064\n",
      "  Precision: 0.4828\n",
      "  Recall: 0.0602\n",
      "  F1-score: 0.1071\n",
      "  ROC AUC: 0.5269\n",
      "------------------------------\n",
      "Results for Dataset 2:\n",
      "  Accuracy: 0.9037\n",
      "  TP rate: 0.1156\n",
      "  FP rate: 0.0185\n",
      "  Precision: 0.3810\n",
      "  Recall: 0.1156\n",
      "  F1-score: 0.1774\n",
      "  ROC AUC: 0.5485\n",
      "------------------------------\n",
      "Results for Dataset 3:\n",
      "  Accuracy: 0.8551\n",
      "  TP rate: 0.2551\n",
      "  FP rate: 0.0856\n",
      "  Precision: 0.2273\n",
      "  Recall: 0.2551\n",
      "  F1-score: 0.2404\n",
      "  ROC AUC: 0.5848\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the classifier for each dataset\n",
    "for X_train, X_test, y_train, y_test, dataset_name in zip(\n",
    "    [X1_train, X2_train, X3_train],\n",
    "    [X1_test, X2_test, X3_test],\n",
    "    [y1_train, y2_train, y3_train],\n",
    "    [y1_test, y2_test, y3_test],\n",
    "    ['Dataset 1', 'Dataset 2', 'Dataset 3']\n",
    "):\n",
    "    # Train the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "    tpr = tp / (tp + fn)\n",
    "    fpr = fp / (fp + tn)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Results for {dataset_name}:\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  TP rate: {tpr:.4f}\")\n",
    "    print(f\"  FP rate: {fpr:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall: {recall:.4f}\")\n",
    "    print(f\"  F1-score: {f1:.4f}\")\n",
    "    print(f\"  ROC AUC: {roc_auc:.4f}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X4 = dataset1.drop('HeartDisease_Yes', axis=1) \n",
    "y4 = dataset1['HeartDisease_Yes']\n",
    "X5 = dataset2.drop('HeartDisease_Yes', axis=1)\n",
    "y5 = dataset2['HeartDisease_Yes']\n",
    "X6 = dataset3.drop('HeartDisease_Yes', axis=1)\n",
    "y6 = dataset3['HeartDisease_Yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X4_train, X4_test, y4_train, y4_test = train_test_split(X4, y4, test_size=0.3, random_state=42)\n",
    "X5_train, X5_test, y5_train,y5_test = train_test_split(X5, y5, test_size=0.3, random_state=42)\n",
    "X6_train, X6_test, y6_train, y6_test = train_test_split(X6, y6, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Dataset 4:\n",
      "  Accuracy: 0.9098\n",
      "  TP rate: 0.0602\n",
      "  FP rate: 0.0064\n",
      "  Precision: 0.4828\n",
      "  Recall: 0.0602\n",
      "  F1-score: 0.1071\n",
      "  ROC AUC: 0.5269\n",
      "------------------------------\n",
      "Results for Dataset 5:\n",
      "  Accuracy: 0.9036\n",
      "  TP rate: 0.1137\n",
      "  FP rate: 0.0185\n",
      "  Precision: 0.3783\n",
      "  Recall: 0.1137\n",
      "  F1-score: 0.1749\n",
      "  ROC AUC: 0.5476\n",
      "------------------------------\n",
      "Results for Dataset 6:\n",
      "  Accuracy: 0.8552\n",
      "  TP rate: 0.2524\n",
      "  FP rate: 0.0852\n",
      "  Precision: 0.2262\n",
      "  Recall: 0.2524\n",
      "  F1-score: 0.2386\n",
      "  ROC AUC: 0.5836\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the classifier for each dataset\n",
    "for X_train, X_test, y_train, y_test, dataset_name in zip(\n",
    "    [X4_train, X5_train, X6_train],\n",
    "    [X4_test, X5_test, X6_test],\n",
    "    [y4_train, y5_train, y6_train],\n",
    "    [y4_test, y5_test, y6_test],\n",
    "    ['Dataset 4', 'Dataset 5', 'Dataset 6']\n",
    "):\n",
    "    # Train the classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "    tpr = tp / (tp + fn)\n",
    "    fpr = fp / (fp + tn)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Results for {dataset_name}:\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  TP rate: {tpr:.4f}\")\n",
    "    print(f\"  FP rate: {fpr:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall: {recall:.4f}\")\n",
    "    print(f\"  F1-score: {f1:.4f}\")\n",
    "    print(f\"  ROC AUC: {roc_auc:.4f}\")\n",
    "    print(\"-\" * 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
